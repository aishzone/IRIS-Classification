#Introduction to IRIS Classification
These are some of the important terms which will help you throughout your wonderful journey in machine learning using python.
##Basic Terminologies in Classification Algorithms
*Dataset: Table with the data from which the machine learns.When used to induce a model, the dataset is called training data.
*Classifier: An algorithm that maps the input data to a specific category.
*Classification model: A classification model tries to draw some conclusion from the input values given for training. It will predict the class labels/categories for the new data.
*Instance: A row in the dataset. Other names for 'instance' are: (data) point, example, observation.
*Feature: A feature is an individual measurable property of a phenomenon being observed.
*Binary Classification: Classification task with two possible outcomes. Eg: Gender classification (Male / Female) , (Yes/No) or (True-1/False-0) question.
*Multi-class classification: Classification with more than two classes. In multi-class classification, each sample is assigned to one and only one target label. Eg: An animal can be a cat or dog but not both at the same time.
*Multi-label classification: Classification task where each sample is mapped to a set of target labels (more than one class). Eg: A news article can be about sports, a person, and location at the same time.

This is all you need to build your first classification model, Surprising right?
##IRIS Classification model
Use case  → Botanist wants to determine the species of an iris flower based on the characteristics of that flower.Attributes including petal length and width ,sepal length and width etc.. are the "features" that determine the classification of the given iris flower.
![Image of setosa,versicolor,verginica](https://cdn-images-1.medium.com/max/800/1*gpWdhDY8Gmo2-OBRT8mQMQ.png)
##Coding
let's start off by displaying the above images on the screen
![Image](https://cdn-images-1.medium.com/max/800/1*gd0p6zJQS-RQD6dAntPU9g.png)
Now we start the actual coding by importing the required datasets for us to train and work with.
